{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44c5b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 03:21:15,794 - root - INFO - Test info\n",
      "2022-05-05 03:21:15,795 - root - DEBUG - Test debug\n",
      "2022-05-05 03:21:15,796 - root - ERROR - Test error\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import os\n",
    "logger = logging.getLogger()\n",
    " \n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    " \n",
    "# Setup file handler\n",
    "fhandler  = logging.FileHandler('my.log')\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "fhandler.setFormatter(formatter)\n",
    " \n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    " \n",
    "# Show the handlers\n",
    "logger.handlers\n",
    " \n",
    "# Log Something\n",
    "logger.info(\"Test info\")\n",
    "logger.debug(\"Test debug\")\n",
    "logger.error(\"Test error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a6d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.data_path = \"/home/qiupp/data/\"\n",
    "        self.file_name = \"FB15K\"\n",
    "        self.ent_num = 10\n",
    "        self.rel_num = 10\n",
    "        self.smooth = 0.1\n",
    "        self.dim = 200\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 1400\n",
    "        self.eval_batch = 500\n",
    "        self.drop_out = 0.5\n",
    "        self.lambd = 0.00001\n",
    "        self.epochs = 400\n",
    "        self.model_path =  \"/home/qiupp/codestore/CrossE/models\"\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    def init_num(self, ent_num, rel_num):\n",
    "        self.ent_num = ent_num\n",
    "        self.rel_num = rel_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13661b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict as ddict\n",
    "class loadData:\n",
    "    def __init__(self, config):\n",
    "#         super(loadData, self).__init__()\n",
    "        self.file_path = config.data_path+config.file_name+\"/\"\n",
    "        self.entity2id = {}\n",
    "        self.rel2id = {}\n",
    "        \n",
    "        logger.info(\"load \"+config.file_name)\n",
    "        self.data = {sql:self.read_file(sql) for sql in ['train', 'valid', 'test']}\n",
    "        logger.info(\"load \"+config.file_name+\" is over\")\n",
    "        \n",
    "        logger.info(\"数据开始处理\")\n",
    "        self.train_hr_tlist, self.train_tr_hlist = self.get_train_list()\n",
    "        \n",
    "        \n",
    "        self.valid_hr_tlist,self.valid_tr_hlist,self.test_hr_tlist,self.test_tr_hlist = self.get_valid_test_list()\n",
    "        logger.info(\"数据处理结束\")\n",
    "        \n",
    "        logger.info(\"ent_num: \"+str(self.get_ent_num()))\n",
    "        logger.info(\"rel_num: \"+str(self.get_rel_num()))\n",
    "        \n",
    "    \n",
    "    def get_ent_num(self):\n",
    "        return len(self.entity2id)\n",
    "    \n",
    "    def get_rel_num(self):\n",
    "        return len(self.rel2id)\n",
    "    \n",
    "    def get_train_list(self):\n",
    "        hr_tlist = ddict(set)\n",
    "        tr_hlist = ddict(set)\n",
    "        \n",
    "        new_hr_tlist = []\n",
    "        new_tr_hlist = []\n",
    "        for (h, r, t) in self.data['train']:\n",
    "            hr_tlist[(h, r)].add(t)\n",
    "            tr_hlist[(t, r)].add(h)\n",
    "        for (h, r, t) in self.data['train']:\n",
    "            new_hr_tlist.append({\"triple\":(h, r), 'labels':hr_tlist[(h, r)]})\n",
    "            new_tr_hlist.append({\"triple\":(t, r), 'labels':tr_hlist[(t, r)]})\n",
    "        return new_hr_tlist, new_tr_hlist\n",
    "    \n",
    "    def get_valid_test_list(self):\n",
    "        hr_tlist = ddict(set)\n",
    "        tr_hlist = ddict(set)\n",
    "        \n",
    "        valid_hr_tlist = []\n",
    "        valid_tr_hlist = []\n",
    "        \n",
    "        test_hr_tlist = []\n",
    "        test_tr_hlist = []\n",
    "        \n",
    "        for sql in ['test', 'valid', 'train']:\n",
    "            for (h, r, t) in self.data[sql]:\n",
    "                hr_tlist[(h, r)].add(t)\n",
    "                tr_hlist[(t, r)].add(h)\n",
    "                \n",
    "        for (h, r, t) in self.data['valid']:\n",
    "            valid_hr_tlist.append({\"triple\":(h, r, t), 'labels':hr_tlist[(h, r)]})\n",
    "            valid_tr_hlist.append({\"triple\":(t, r, h), 'labels':tr_hlist[(t, r)]})\n",
    "        \n",
    "        for (h, r, t) in self.data['test']:\n",
    "            test_hr_tlist.append({\"triple\":(h, r, t), 'labels':hr_tlist[(h, r)]})\n",
    "            test_tr_hlist.append({\"triple\":(t, r, h), 'labels':tr_hlist[(t, r)]})\n",
    "        return valid_hr_tlist, valid_tr_hlist, test_hr_tlist, test_tr_hlist      \n",
    "        \n",
    "    def get_entity_id(self, entity):\n",
    "        if not entity in self.entity2id.keys():\n",
    "            self.entity2id[entity] = len(self.entity2id)\n",
    "        return self.entity2id[entity]\n",
    "    \n",
    "    def get_rel_id(self, rel):\n",
    "        if not rel in self.rel2id.keys():\n",
    "            self.rel2id[rel] = len(self.rel2id)\n",
    "        return self.rel2id[rel]\n",
    "    \n",
    "    def get_triple(self, line):\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        return tuple((self.get_entity_id(parts[0]), self.get_rel_id(parts[1]), self.get_entity_id(parts[2])))\n",
    "    \n",
    "    def read_file(self, text):\n",
    "        triples = []\n",
    "        with open(self.file_path+text+\".txt\", 'r')as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            triples.append(self.get_triple(line))\n",
    "        return triples\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02027a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class myTrainDataSet(Dataset):\n",
    "    def __init__(self, myLoadData, config):\n",
    "        super(myTrainDataSet, self).__init__()\n",
    "        self.data_hr_tlist = myLoadData.train_hr_tlist\n",
    "        self.data_tr_hlist = myLoadData.train_tr_hlist\n",
    "        self.ent_num = config.ent_num\n",
    "        self.smooth = config.smooth\n",
    "    def __len__(self):\n",
    "        return len(self.data_hr_tlist)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        h_triple = torch.LongTensor(self.data_hr_tlist[index]['triple'])\n",
    "        h_list = torch.Tensor(self.getlabel(self.data_hr_tlist[index]['labels']))\n",
    "        \n",
    "        t_triple = torch.LongTensor(self.data_tr_hlist[index]['triple'])\n",
    "        t_list = torch.Tensor(self.getlabel(self.data_tr_hlist[index]['labels']))\n",
    "        \n",
    "        return h_triple,h_list, t_triple,t_list \n",
    "    \n",
    "    def getlabel(self, labels_list):\n",
    "        labels = np.zeros(self.ent_num)\n",
    "        for label in labels_list:\n",
    "            labels[label] = 1\n",
    "        if self.smooth != 0.0:\n",
    "            labels = (1 -  self.smooth)*labels + self.smooth/self.ent_num\n",
    "        return labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c881ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myTestDateSet(Dataset):\n",
    "    def __init__(self, myLoadData, config, file_type):\n",
    "        self.ent_num = config.ent_num\n",
    "        if file_type == 'test':\n",
    "            self.hr_tlist =  myLoadData.test_hr_tlist\n",
    "            self.tr_hlist = myLoadData.test_tr_hlist\n",
    "        else:\n",
    "            \n",
    "            self.hr_tlist = myLoadData.valid_hr_tlist\n",
    "            self.tr_hlist = myLoadData.valid_tr_hlist\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hr_tlist)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fact_h = self.hr_tlist[index]['triple']\n",
    "        fact_t = self.tr_hlist[index]['triple']\n",
    "        \n",
    "        label_h = self.hr_tlist[index]['labels']\n",
    "        label_t = self.tr_hlist[index]['labels']\n",
    "        return torch.LongTensor(fact_h), torch.Tensor(self.getlabel(label_h)), torch.LongTensor(fact_t), torch.LongTensor(self.getlabel(label_t))\n",
    "    def getlabel(self, labels_list):\n",
    "        labels = np.zeros(self.ent_num)\n",
    "        for label in labels_list:\n",
    "            labels[label] = 1\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e357e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure:\n",
    "    def __init__(self):\n",
    "        self.hit1 = 0.0\n",
    "        self.hit3 = 0.0\n",
    "        self.hit10 = 0.0\n",
    "        self.mr = 0.0\n",
    "        self.mrr = 0.0\n",
    "    \n",
    "    def update(self, rank):\n",
    "        if rank == 1:\n",
    "            self.hit1 += 1\n",
    "        if rank <= 3:\n",
    "            self.hit3 += 1\n",
    "        if rank <= 10:\n",
    "            self.hit10 += 1\n",
    "        self.mr += rank\n",
    "        self.mrr += 1.0/rank\n",
    "    def deal(self, fact_num):\n",
    "        self.hit1 /= fact_num\n",
    "        self.hit3 /= fact_num\n",
    "        self.hit10 /= fact_num\n",
    "        self.mr /= fact_num\n",
    "        self.mrr /= fact_num\n",
    "        return self.mrr\n",
    "    def init(self):\n",
    "        self.hit1 = 0.0\n",
    "        self.hit3 = 0.0\n",
    "        self.hit10 = 0.0\n",
    "        self.mr = 0.0\n",
    "        self.mrr = 0.0\n",
    "    def print_(self):\n",
    "        logger.info(\"--------------------\")\n",
    "        logger.info(\"hit1: \"+str(self.hit1))\n",
    "        logger.info(\"hit3: \"+str(self.hit3))\n",
    "        logger.info(\"hit10: \"+str(self.hit10))\n",
    "        logger.info(\"mr: \"+ str(self.mr))\n",
    "        logger.info(\"mrr: \"+str(self.mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8db4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CrossE, self).__init__()\n",
    "        self.lambd = config.lambd\n",
    "        \n",
    "        self.ent_embedding  = nn.Embedding(config.ent_num, config.dim)\n",
    "        \n",
    "        self.rel_embedding = nn.Embedding(config.rel_num, config.dim)\n",
    "        \n",
    "        self.rel_rev_embedding = nn.Embedding(config.rel_num, config.dim)\n",
    "        \n",
    "        self.h_weight = nn.Embedding(config.rel_num, config.dim)\n",
    "        \n",
    "        self.t_weight = nn.Embedding(config.rel_num, config.dim)\n",
    "        \n",
    "        self.init()\n",
    "        \n",
    "        self.h_t_bias = nn.Parameter(torch.zeros([config.ent_num]), requires_grad= True)\n",
    "        \n",
    "        self.t_h_bias = nn.Parameter(torch.zeros([config.ent_num]), requires_grad= True)\n",
    "        \n",
    "        self.h_bias = nn.Parameter(torch.zeros([config.dim]), requires_grad= True)\n",
    "        \n",
    "        self.t_bias = nn.Parameter(torch.zeros([config.dim]), requires_grad= True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.drop_out)\n",
    "        self.loss = nn.BCELoss()\n",
    "    def init(self):\n",
    "        nn.init.xavier_normal_(self.ent_embedding.weight.data)\n",
    "        nn.init.xavier_normal_(self.rel_embedding.weight.data)\n",
    "        nn.init.xavier_normal_(self.rel_rev_embedding.weight.data)\n",
    "        nn.init.xavier_normal_(self.h_weight.weight.data)\n",
    "        nn.init.xavier_normal_(self.t_weight.weight.data)\n",
    "    def regulation(self):\n",
    "        return ((torch.norm(self.ent_embedding.weight, 2)**2)\\\n",
    "                +(torch.norm(self.rel_embedding.weight, 2)**2)\\\n",
    "                +(torch.norm(self.rel_rev_embedding.weight, 2)**2)\\\n",
    "                +(torch.norm(self.h_weight.weight, 2)**2)\\\n",
    "                +(torch.norm(self.t_weight.weight, 2)**2))/5\n",
    "#         return (torch.sum(torch.abs(self.ent_embedding.weight))\\\n",
    "#                 +torch.sum(torch.abs(self.rel_embedding.weight))\\\n",
    "#                 +torch.sum(torch.abs(self.rel_rev_embedding.weight))\\\n",
    "#                 +torch.sum(torch.abs(self.h_weight.weight))\\\n",
    "#                 +torch.sum(torch.abs(self.t_weight.weight)))/5\n",
    "    \n",
    "    \n",
    "    def forward(self,h_list, h_labels, t_list, t_labels):\n",
    "        h_h = h_list[:, 0]\n",
    "        h_r = h_list[:, 1]\n",
    "        \n",
    "        t_t = t_list[:, 0]\n",
    "        t_r = t_list[:, 1]\n",
    "        \n",
    "        h_emb = self.ent_embedding(h_h)\n",
    "        r_emb = self.rel_embedding(h_r)\n",
    "        h_w = self.h_weight(h_r)\n",
    "        \n",
    "        h_res = h_emb*h_w +  r_emb*h_emb*h_w\n",
    "        \n",
    "        hrt = torch.mm(self.dropout(torch.tanh(h_res + self.h_bias)),self.ent_embedding.weight.transpose(0, 1))\n",
    "        hrt += self.h_t_bias.expand_as(hrt)\n",
    "#         print(hrt.shape)\n",
    "        hrt = torch.sigmoid(hrt)\n",
    "    \n",
    "        hrt_loss = -torch.sum(torch.log(torch.clamp(hrt, 1e-10, 1.0)) * h_labels\\\n",
    "                + torch.log(torch.clamp(1 - hrt, 1e-10, 1.0)) *( 1-h_labels))\n",
    "    \n",
    "    \n",
    "        \n",
    "        t_emb = self.ent_embedding(t_t)\n",
    "        r_rev = self.rel_rev_embedding(t_r)\n",
    "        t_w = self.t_weight(t_r)\n",
    "        \n",
    "        t_res = t_emb*t_w + r_rev*t_emb*t_w\n",
    "        trh = torch.mm(self.dropout(torch.tanh(t_res + self.t_bias)), self.ent_embedding.weight.transpose(0, 1))\n",
    "        trh += self.t_h_bias.expand_as(trh)\n",
    "        \n",
    "        trh = torch.sigmoid(trh)\n",
    "        \n",
    "        trh_loss = -torch.sum(torch.log(torch.clamp(trh, 1e-10, 1.0)) *  t_labels\\\n",
    "                + torch.log(torch.clamp(1 - trh, 1e-10, 1.0)) * (1-t_labels))\n",
    "            \n",
    "#         print(self.regulation())\n",
    "        \n",
    "        return hrt_loss + trh_loss + self.lambd*self.regulation()\n",
    "    \n",
    "    def pred(self, h_list, h_labels, t_list, t_labels):\n",
    "        h_h = h_list[:, 0]\n",
    "        h_r = h_list[:, 1]\n",
    "        \n",
    "        t_t = t_list[:, 0]\n",
    "        t_r = t_list[:, 1]\n",
    "        \n",
    "        h_emb = self.ent_embedding(h_h)\n",
    "        r_emb = self.rel_embedding(h_r)\n",
    "        h_w = self.h_weight(h_r)\n",
    "        \n",
    "        h_res = h_emb*h_w +  r_emb*h_emb*h_w\n",
    "        \n",
    "        hrt = torch.mm(torch.tanh(h_res + self.h_bias),self.ent_embedding.weight.transpose(0, 1))\n",
    "        hrt += self.h_t_bias.expand_as(hrt)\n",
    "#         print(hrt.shape)\n",
    "        hrt = torch.sigmoid(hrt)\n",
    "        \n",
    "        t_emb = self.ent_embedding(t_t)\n",
    "        r_rev = self.rel_rev_embedding(t_r)\n",
    "        t_w = self.t_weight(t_r)\n",
    "        \n",
    "        t_res = t_emb*t_w + r_rev*t_emb*t_w\n",
    "        trh = torch.mm(torch.tanh(t_res + self.t_bias), self.ent_embedding.weight.transpose(0, 1))\n",
    "        trh += self.t_h_bias.expand_as(trh)\n",
    "        \n",
    "        trh = torch.sigmoid(trh)\n",
    "        \n",
    "        return hrt.detach(), trh.detach()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add40d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, myLoadData, config, model):\n",
    "        self.model = model.to(config.device)\n",
    "        self.device = config.device\n",
    "        self.measure = Measure()\n",
    "        self.train_loader = DataLoader(myTrainDataSet(myLoadData, config), batch_size = config.batch_size, shuffle = True)\n",
    "        self.config = config\n",
    "        testdata = myTestDateSet(myLoadData, config, 'valid')\n",
    "        self.test_loader = DataLoader(testdata, batch_size = config.eval_batch, shuffle = True)\n",
    "#         self.epochs = config.epochs\n",
    "        self.fact_num = len(testdata)\n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr = self.config.lr)\n",
    "        for epoch in range(1, self.config.epochs+1):\n",
    "            self.model.train()\n",
    "            tot_loss = 0\n",
    "            for i, (h, h_l, t,t_l) in enumerate(self.train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                h = h.to(self.device)\n",
    "                h_l = h_l.to(self.device)\n",
    "                t = t.to(self.device)\n",
    "                t_l = t_l.to(self.device)\n",
    "                \n",
    "                loss = self.model(h, h_l, t, t_l)\n",
    "                loss.backward()\n",
    "                tot_loss += loss.cpu().item()\n",
    "                optimizer.step()\n",
    "            logger.info(str(epoch)+\"     loss: \"+str(tot_loss))\n",
    "            self.measure.init()\n",
    "            self.eval_valid()\n",
    "    def save_models(self):\n",
    "        if not os.path.exists(self.config.model_path):\n",
    "            os.mkdir(self.config.model_path)\n",
    "        torch.save(self.model, self.config.model_path+\"/\"+self.config.file_name+\"-best_model.pkl\")\n",
    "        \n",
    "    def eval_valid(self):\n",
    "        self.model.eval()\n",
    "        best_acc = 0.0\n",
    "        cn = 0\n",
    "        for i, (h, h_l, t,t_l) in enumerate(self.test_loader):\n",
    "            cn += h.shape[0]\n",
    "            \n",
    "            h = h.to(self.device)\n",
    "            h_l = h_l.to(self.device)\n",
    "            t = t.to(self.device)\n",
    "            t_l = t_l.to(self.device)\n",
    "            h_pred, t_pred= self.model.pred(h, h_l, t, t_l)\n",
    "            \n",
    "            h_target = h[:,-1]\n",
    "            t_target = t[:, -1]\n",
    "            self.pred(h_pred, h_l, h_target)\n",
    "            self.pred(t_pred, t_l, t_target)\n",
    "#         if self.fact_num == cn:\n",
    "#             print(\"kjkjkj-----------\")\n",
    "#         else:\n",
    "#             print(\"------------------\"+str(cn))\n",
    "        acc = self.measure.deal(self.fact_num*2)\n",
    "        if acc > best_acc:\n",
    "            self.save_models()\n",
    "        self.measure.print_()\n",
    "    \n",
    "    def pred(self, pred, labels, t):\n",
    "        batch = pred.shape[0]\n",
    "        pred_size = torch.arange(batch)\n",
    "        target = pred[pred_size,t]\n",
    "        pred = torch.where(labels.byte(), torch.zeros_like(pred), pred)\n",
    "        pred[pred_size, t] = target\n",
    "        pred = pred.cpu().numpy()\n",
    "        t = t.cpu().numpy()\n",
    "        for i in range(batch):\n",
    "            e = t[i]\n",
    "            one_pred = pred[i]\n",
    "            aim = one_pred[e]\n",
    "            sc = np.delete(one_pred, e)\n",
    "            sc = np.insert(sc, 0,aim)\n",
    "            rank = (sc[0] <= sc).sum()\n",
    "            self.measure.update(rank)\n",
    "                            \n",
    "                        \n",
    "        \n",
    "            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cfdc9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 03:21:17,998 - root - INFO - load FB15K\n",
      "2022-05-05 03:21:19,864 - root - INFO - load FB15K is over\n",
      "2022-05-05 03:21:19,865 - root - INFO - 数据开始处理\n",
      "2022-05-05 03:21:27,848 - root - INFO - 数据处理结束\n",
      "2022-05-05 03:21:27,849 - root - INFO - ent_num: 14951\n",
      "2022-05-05 03:21:27,850 - root - INFO - rel_num: 1345\n",
      "2022-05-05 03:24:34,629 - root - INFO - 1     loss: 2171157840.0\n",
      "/tmp/ipykernel_670041/58581932.py:66: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n",
      "  pred = torch.where(labels.byte(), torch.zeros_like(pred), pred)\n",
      "2022-05-05 03:24:57,825 - root - INFO - --------------------\n",
      "2022-05-05 03:24:57,826 - root - INFO - hit1: 0.00453\n",
      "2022-05-05 03:24:57,826 - root - INFO - hit3: 0.01992\n",
      "2022-05-05 03:24:57,827 - root - INFO - hit10: 0.03627\n",
      "2022-05-05 03:24:57,827 - root - INFO - mr: 6102.83665\n",
      "2022-05-05 03:24:57,828 - root - INFO - mrr: 0.016292392055911563\n",
      "2022-05-05 03:27:58,123 - root - INFO - 2     loss: 474990671.71875\n",
      "2022-05-05 03:28:20,900 - root - INFO - --------------------\n",
      "2022-05-05 03:28:20,900 - root - INFO - hit1: 0.01025\n",
      "2022-05-05 03:28:20,901 - root - INFO - hit3: 0.022\n",
      "2022-05-05 03:28:20,901 - root - INFO - hit10: 0.04515\n",
      "2022-05-05 03:28:20,902 - root - INFO - mr: 5452.49035\n",
      "2022-05-05 03:28:20,902 - root - INFO - mrr: 0.02096143680480412\n",
      "2022-05-05 03:31:19,235 - root - INFO - 3     loss: 351125259.453125\n",
      "2022-05-05 03:31:42,461 - root - INFO - --------------------\n",
      "2022-05-05 03:31:42,463 - root - INFO - hit1: 0.00655\n",
      "2022-05-05 03:31:42,464 - root - INFO - hit3: 0.01802\n",
      "2022-05-05 03:31:42,465 - root - INFO - hit10: 0.05874\n",
      "2022-05-05 03:31:42,466 - root - INFO - mr: 5232.98661\n",
      "2022-05-05 03:31:42,467 - root - INFO - mrr: 0.02189554273719678\n",
      "2022-05-05 03:34:42,267 - root - INFO - 4     loss: 269863893.640625\n",
      "2022-05-05 03:35:05,342 - root - INFO - --------------------\n",
      "2022-05-05 03:35:05,345 - root - INFO - hit1: 0.02508\n",
      "2022-05-05 03:35:05,347 - root - INFO - hit3: 0.06217\n",
      "2022-05-05 03:35:05,347 - root - INFO - hit10: 0.08552\n",
      "2022-05-05 03:35:05,348 - root - INFO - mr: 4858.94316\n",
      "2022-05-05 03:35:05,349 - root - INFO - mrr: 0.048845033915055576\n",
      "2022-05-05 03:38:04,965 - root - INFO - 5     loss: 225939229.14453125\n",
      "2022-05-05 03:38:27,786 - root - INFO - --------------------\n",
      "2022-05-05 03:38:27,787 - root - INFO - hit1: 0.04565\n",
      "2022-05-05 03:38:27,788 - root - INFO - hit3: 0.07275\n",
      "2022-05-05 03:38:27,789 - root - INFO - hit10: 0.09824\n",
      "2022-05-05 03:38:27,790 - root - INFO - mr: 4152.11823\n",
      "2022-05-05 03:38:27,790 - root - INFO - mrr: 0.0660937035243623\n",
      "2022-05-05 03:41:28,049 - root - INFO - 6     loss: 199967418.1484375\n",
      "2022-05-05 03:41:50,964 - root - INFO - --------------------\n",
      "2022-05-05 03:41:50,965 - root - INFO - hit1: 0.06926\n",
      "2022-05-05 03:41:50,965 - root - INFO - hit3: 0.10495\n",
      "2022-05-05 03:41:50,966 - root - INFO - hit10: 0.15083\n",
      "2022-05-05 03:41:50,966 - root - INFO - mr: 3518.22793\n",
      "2022-05-05 03:41:50,967 - root - INFO - mrr: 0.09833860885171923\n",
      "2022-05-05 03:44:50,410 - root - INFO - 7     loss: 179533251.30859375\n",
      "2022-05-05 03:45:13,676 - root - INFO - --------------------\n",
      "2022-05-05 03:45:13,677 - root - INFO - hit1: 0.10127\n",
      "2022-05-05 03:45:13,678 - root - INFO - hit3: 0.14905\n",
      "2022-05-05 03:45:13,678 - root - INFO - hit10: 0.20005\n",
      "2022-05-05 03:45:13,678 - root - INFO - mr: 3079.52488\n",
      "2022-05-05 03:45:13,679 - root - INFO - mrr: 0.13671908632315577\n",
      "2022-05-05 03:48:14,545 - root - INFO - 8     loss: 163820437.5546875\n",
      "2022-05-05 03:48:38,079 - root - INFO - --------------------\n",
      "2022-05-05 03:48:38,080 - root - INFO - hit1: 0.12043\n",
      "2022-05-05 03:48:38,081 - root - INFO - hit3: 0.17646\n",
      "2022-05-05 03:48:38,082 - root - INFO - hit10: 0.23745\n",
      "2022-05-05 03:48:38,083 - root - INFO - mr: 2700.5656\n",
      "2022-05-05 03:48:38,083 - root - INFO - mrr: 0.16187274682855612\n",
      "2022-05-05 03:51:39,171 - root - INFO - 9     loss: 151999241.359375\n",
      "2022-05-05 03:52:02,470 - root - INFO - --------------------\n",
      "2022-05-05 03:52:02,471 - root - INFO - hit1: 0.14413\n",
      "2022-05-05 03:52:02,472 - root - INFO - hit3: 0.20326\n",
      "2022-05-05 03:52:02,473 - root - INFO - hit10: 0.2721\n",
      "2022-05-05 03:52:02,473 - root - INFO - mr: 2348.13578\n",
      "2022-05-05 03:52:02,474 - root - INFO - mrr: 0.1891729831415469\n",
      "2022-05-05 03:55:02,044 - root - INFO - 10     loss: 142722158.26953125\n",
      "2022-05-05 03:55:25,802 - root - INFO - --------------------\n",
      "2022-05-05 03:55:25,803 - root - INFO - hit1: 0.16619\n",
      "2022-05-05 03:55:25,804 - root - INFO - hit3: 0.22833\n",
      "2022-05-05 03:55:25,805 - root - INFO - hit10: 0.30429\n",
      "2022-05-05 03:55:25,806 - root - INFO - mr: 2042.81773\n",
      "2022-05-05 03:55:25,807 - root - INFO - mrr: 0.21382209229875912\n",
      "2022-05-05 03:58:25,521 - root - INFO - 11     loss: 135243427.0234375\n",
      "2022-05-05 03:58:48,644 - root - INFO - --------------------\n",
      "2022-05-05 03:58:48,646 - root - INFO - hit1: 0.18533\n",
      "2022-05-05 03:58:48,647 - root - INFO - hit3: 0.25228\n",
      "2022-05-05 03:58:48,648 - root - INFO - hit10: 0.33408\n",
      "2022-05-05 03:58:48,648 - root - INFO - mr: 1775.28387\n",
      "2022-05-05 03:58:48,649 - root - INFO - mrr: 0.23648929170316388\n",
      "2022-05-05 04:01:48,495 - root - INFO - 12     loss: 128932599.9140625\n",
      "2022-05-05 04:02:11,909 - root - INFO - --------------------\n",
      "2022-05-05 04:02:11,910 - root - INFO - hit1: 0.20425\n",
      "2022-05-05 04:02:11,911 - root - INFO - hit3: 0.27521\n",
      "2022-05-05 04:02:11,912 - root - INFO - hit10: 0.36126\n",
      "2022-05-05 04:02:11,914 - root - INFO - mr: 1507.65568\n",
      "2022-05-05 04:02:11,915 - root - INFO - mrr: 0.25805746067797974\n",
      "2022-05-05 04:05:11,483 - root - INFO - 13     loss: 123673220.109375\n",
      "2022-05-05 04:05:35,671 - root - INFO - --------------------\n",
      "2022-05-05 04:05:35,672 - root - INFO - hit1: 0.21992\n",
      "2022-05-05 04:05:35,673 - root - INFO - hit3: 0.29597\n",
      "2022-05-05 04:05:35,673 - root - INFO - hit10: 0.38655\n",
      "2022-05-05 04:05:35,674 - root - INFO - mr: 1254.69044\n",
      "2022-05-05 04:05:35,674 - root - INFO - mrr: 0.27731290899282707\n",
      "2022-05-05 04:08:35,213 - root - INFO - 14     loss: 119167287.27734375\n",
      "2022-05-05 04:08:58,576 - root - INFO - --------------------\n",
      "2022-05-05 04:08:58,577 - root - INFO - hit1: 0.23737\n",
      "2022-05-05 04:08:58,577 - root - INFO - hit3: 0.3187\n",
      "2022-05-05 04:08:58,578 - root - INFO - hit10: 0.41235\n",
      "2022-05-05 04:08:58,579 - root - INFO - mr: 1027.33004\n",
      "2022-05-05 04:08:58,580 - root - INFO - mrr: 0.29742954207433897\n",
      "2022-05-05 04:11:59,102 - root - INFO - 15     loss: 115386467.66601562\n",
      "2022-05-05 04:12:22,503 - root - INFO - --------------------\n",
      "2022-05-05 04:12:22,504 - root - INFO - hit1: 0.25426\n",
      "2022-05-05 04:12:22,505 - root - INFO - hit3: 0.33981\n",
      "2022-05-05 04:12:22,506 - root - INFO - hit10: 0.43932\n",
      "2022-05-05 04:12:22,507 - root - INFO - mr: 851.39453\n",
      "2022-05-05 04:12:22,508 - root - INFO - mrr: 0.31735916563113986\n",
      "2022-05-05 04:15:24,813 - root - INFO - 16     loss: 112038756.625\n",
      "2022-05-05 04:15:49,614 - root - INFO - --------------------\n",
      "2022-05-05 04:15:49,615 - root - INFO - hit1: 0.27246\n",
      "2022-05-05 04:15:49,615 - root - INFO - hit3: 0.362\n",
      "2022-05-05 04:15:49,616 - root - INFO - hit10: 0.46499\n",
      "2022-05-05 04:15:49,616 - root - INFO - mr: 733.16416\n",
      "2022-05-05 04:15:49,616 - root - INFO - mrr: 0.33825133492126674\n",
      "2022-05-05 04:18:55,361 - root - INFO - 17     loss: 109088153.234375\n",
      "2022-05-05 04:19:19,176 - root - INFO - --------------------\n",
      "2022-05-05 04:19:19,178 - root - INFO - hit1: 0.28882\n",
      "2022-05-05 04:19:19,180 - root - INFO - hit3: 0.38171\n",
      "2022-05-05 04:19:19,181 - root - INFO - hit10: 0.48505\n",
      "2022-05-05 04:19:19,182 - root - INFO - mr: 642.18072\n",
      "2022-05-05 04:19:19,183 - root - INFO - mrr: 0.35610920139802305\n",
      "2022-05-05 04:22:25,312 - root - INFO - 18     loss: 106737432.42382812\n",
      "2022-05-05 04:22:49,280 - root - INFO - --------------------\n",
      "2022-05-05 04:22:49,281 - root - INFO - hit1: 0.29995\n",
      "2022-05-05 04:22:49,281 - root - INFO - hit3: 0.39647\n",
      "2022-05-05 04:22:49,282 - root - INFO - hit10: 0.50174\n",
      "2022-05-05 04:22:49,282 - root - INFO - mr: 566.47307\n",
      "2022-05-05 04:22:49,282 - root - INFO - mrr: 0.36912653035749987\n",
      "2022-05-05 04:25:56,252 - root - INFO - 19     loss: 104585546.16601562\n",
      "2022-05-05 04:26:20,301 - root - INFO - --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 04:26:20,302 - root - INFO - hit1: 0.31274\n",
      "2022-05-05 04:26:20,303 - root - INFO - hit3: 0.41\n",
      "2022-05-05 04:26:20,304 - root - INFO - hit10: 0.51623\n",
      "2022-05-05 04:26:20,304 - root - INFO - mr: 503.65031\n",
      "2022-05-05 04:26:20,305 - root - INFO - mrr: 0.38251550919659544\n",
      "2022-05-05 04:29:28,580 - root - INFO - 20     loss: 102704020.6953125\n",
      "2022-05-05 04:29:52,430 - root - INFO - --------------------\n",
      "2022-05-05 04:29:52,432 - root - INFO - hit1: 0.32327\n",
      "2022-05-05 04:29:52,433 - root - INFO - hit3: 0.42155\n",
      "2022-05-05 04:29:52,433 - root - INFO - hit10: 0.52992\n",
      "2022-05-05 04:29:52,433 - root - INFO - mr: 451.36334\n",
      "2022-05-05 04:29:52,434 - root - INFO - mrr: 0.3938698936538486\n",
      "2022-05-05 04:33:00,144 - root - INFO - 21     loss: 101124022.23828125\n",
      "2022-05-05 04:33:24,041 - root - INFO - --------------------\n",
      "2022-05-05 04:33:24,043 - root - INFO - hit1: 0.33183\n",
      "2022-05-05 04:33:24,044 - root - INFO - hit3: 0.43325\n",
      "2022-05-05 04:33:24,045 - root - INFO - hit10: 0.54257\n",
      "2022-05-05 04:33:24,045 - root - INFO - mr: 407.88226\n",
      "2022-05-05 04:33:24,046 - root - INFO - mrr: 0.4038614924925912\n",
      "2022-05-05 04:36:32,212 - root - INFO - 22     loss: 99626034.40234375\n",
      "2022-05-05 04:36:57,222 - root - INFO - --------------------\n",
      "2022-05-05 04:36:57,223 - root - INFO - hit1: 0.33916\n",
      "2022-05-05 04:36:57,224 - root - INFO - hit3: 0.44213\n",
      "2022-05-05 04:36:57,225 - root - INFO - hit10: 0.55327\n",
      "2022-05-05 04:36:57,226 - root - INFO - mr: 372.71715\n",
      "2022-05-05 04:36:57,226 - root - INFO - mrr: 0.4121196509013642\n",
      "2022-05-05 04:40:03,048 - root - INFO - 23     loss: 98364538.16992188\n",
      "2022-05-05 04:40:26,816 - root - INFO - --------------------\n",
      "2022-05-05 04:40:26,817 - root - INFO - hit1: 0.34626\n",
      "2022-05-05 04:40:26,817 - root - INFO - hit3: 0.45272\n",
      "2022-05-05 04:40:26,818 - root - INFO - hit10: 0.56331\n",
      "2022-05-05 04:40:26,818 - root - INFO - mr: 343.85262\n",
      "2022-05-05 04:40:26,819 - root - INFO - mrr: 0.420582306874512\n",
      "2022-05-05 04:43:33,078 - root - INFO - 24     loss: 97270699.27148438\n",
      "2022-05-05 04:43:57,289 - root - INFO - --------------------\n",
      "2022-05-05 04:43:57,290 - root - INFO - hit1: 0.35214\n",
      "2022-05-05 04:43:57,291 - root - INFO - hit3: 0.46016\n",
      "2022-05-05 04:43:57,291 - root - INFO - hit10: 0.57108\n",
      "2022-05-05 04:43:57,292 - root - INFO - mr: 318.74233\n",
      "2022-05-05 04:43:57,292 - root - INFO - mrr: 0.42728677439081797\n",
      "2022-05-05 04:47:04,445 - root - INFO - 25     loss: 96216258.87304688\n",
      "2022-05-05 04:47:29,261 - root - INFO - --------------------\n",
      "2022-05-05 04:47:29,262 - root - INFO - hit1: 0.35897\n",
      "2022-05-05 04:47:29,263 - root - INFO - hit3: 0.46655\n",
      "2022-05-05 04:47:29,264 - root - INFO - hit10: 0.579\n",
      "2022-05-05 04:47:29,265 - root - INFO - mr: 301.1071\n",
      "2022-05-05 04:47:29,267 - root - INFO - mrr: 0.43429239620496723\n",
      "2022-05-05 04:50:37,922 - root - INFO - 26     loss: 95317036.5546875\n",
      "2022-05-05 04:51:01,739 - root - INFO - --------------------\n",
      "2022-05-05 04:51:01,740 - root - INFO - hit1: 0.36482\n",
      "2022-05-05 04:51:01,741 - root - INFO - hit3: 0.47441\n",
      "2022-05-05 04:51:01,741 - root - INFO - hit10: 0.58712\n",
      "2022-05-05 04:51:01,742 - root - INFO - mr: 284.62429\n",
      "2022-05-05 04:51:01,743 - root - INFO - mrr: 0.44103402046437656\n",
      "2022-05-05 04:54:09,944 - root - INFO - 27     loss: 94533269.10546875\n",
      "2022-05-05 04:54:33,557 - root - INFO - --------------------\n",
      "2022-05-05 04:54:33,558 - root - INFO - hit1: 0.36949\n",
      "2022-05-05 04:54:33,559 - root - INFO - hit3: 0.48059\n",
      "2022-05-05 04:54:33,560 - root - INFO - hit10: 0.59265\n",
      "2022-05-05 04:54:33,561 - root - INFO - mr: 272.45994\n",
      "2022-05-05 04:54:33,562 - root - INFO - mrr: 0.44631114521832727\n",
      "2022-05-05 04:57:40,916 - root - INFO - 28     loss: 93747110.41210938\n",
      "2022-05-05 04:58:04,950 - root - INFO - --------------------\n",
      "2022-05-05 04:58:04,951 - root - INFO - hit1: 0.37439\n",
      "2022-05-05 04:58:04,952 - root - INFO - hit3: 0.48676\n",
      "2022-05-05 04:58:04,952 - root - INFO - hit10: 0.59878\n",
      "2022-05-05 04:58:04,953 - root - INFO - mr: 260.88284\n",
      "2022-05-05 04:58:04,954 - root - INFO - mrr: 0.45187236922920837\n",
      "2022-05-05 05:01:12,018 - root - INFO - 29     loss: 93016023.77148438\n",
      "2022-05-05 05:01:36,920 - root - INFO - --------------------\n",
      "2022-05-05 05:01:36,921 - root - INFO - hit1: 0.37849\n",
      "2022-05-05 05:01:36,922 - root - INFO - hit3: 0.49205\n",
      "2022-05-05 05:01:36,922 - root - INFO - hit10: 0.60429\n",
      "2022-05-05 05:01:36,923 - root - INFO - mr: 251.70786\n",
      "2022-05-05 05:01:36,924 - root - INFO - mrr: 0.45630589049372333\n",
      "2022-05-05 05:04:42,652 - root - INFO - 30     loss: 92408468.78515625\n",
      "2022-05-05 05:05:06,320 - root - INFO - --------------------\n",
      "2022-05-05 05:05:06,322 - root - INFO - hit1: 0.38226\n",
      "2022-05-05 05:05:06,322 - root - INFO - hit3: 0.49708\n",
      "2022-05-05 05:05:06,323 - root - INFO - hit10: 0.60915\n",
      "2022-05-05 05:05:06,324 - root - INFO - mr: 243.60476\n",
      "2022-05-05 05:05:06,325 - root - INFO - mrr: 0.4608201619208875\n",
      "2022-05-05 05:08:13,651 - root - INFO - 31     loss: 91860343.546875\n",
      "2022-05-05 05:08:37,417 - root - INFO - --------------------\n",
      "2022-05-05 05:08:37,418 - root - INFO - hit1: 0.38699\n",
      "2022-05-05 05:08:37,422 - root - INFO - hit3: 0.50199\n",
      "2022-05-05 05:08:37,424 - root - INFO - hit10: 0.61409\n",
      "2022-05-05 05:08:37,425 - root - INFO - mr: 236.84985\n",
      "2022-05-05 05:08:37,426 - root - INFO - mrr: 0.46566723632048046\n",
      "2022-05-05 05:11:44,945 - root - INFO - 32     loss: 91293706.453125\n",
      "2022-05-05 05:12:09,364 - root - INFO - --------------------\n",
      "2022-05-05 05:12:09,365 - root - INFO - hit1: 0.38916\n",
      "2022-05-05 05:12:09,366 - root - INFO - hit3: 0.50618\n",
      "2022-05-05 05:12:09,366 - root - INFO - hit10: 0.61862\n",
      "2022-05-05 05:12:09,367 - root - INFO - mr: 229.80734\n",
      "2022-05-05 05:12:09,368 - root - INFO - mrr: 0.4688686684344822\n",
      "2022-05-05 05:15:17,569 - root - INFO - 33     loss: 90816161.05078125\n",
      "2022-05-05 05:15:41,360 - root - INFO - --------------------\n",
      "2022-05-05 05:15:41,372 - root - INFO - hit1: 0.39258\n",
      "2022-05-05 05:15:41,373 - root - INFO - hit3: 0.51037\n",
      "2022-05-05 05:15:41,374 - root - INFO - hit10: 0.62251\n",
      "2022-05-05 05:15:41,375 - root - INFO - mr: 223.48141\n",
      "2022-05-05 05:15:41,376 - root - INFO - mrr: 0.47242403339563344\n",
      "2022-05-05 05:18:49,475 - root - INFO - 34     loss: 90259071.74023438\n",
      "2022-05-05 05:19:13,415 - root - INFO - --------------------\n",
      "2022-05-05 05:19:13,416 - root - INFO - hit1: 0.39502\n",
      "2022-05-05 05:19:13,417 - root - INFO - hit3: 0.51327\n",
      "2022-05-05 05:19:13,417 - root - INFO - hit10: 0.62643\n",
      "2022-05-05 05:19:13,418 - root - INFO - mr: 218.44187\n",
      "2022-05-05 05:19:13,418 - root - INFO - mrr: 0.475328226600325\n",
      "2022-05-05 05:22:20,797 - root - INFO - 35     loss: 89858655.83984375\n",
      "2022-05-05 05:22:44,490 - root - INFO - --------------------\n",
      "2022-05-05 05:22:44,491 - root - INFO - hit1: 0.39832\n",
      "2022-05-05 05:22:44,492 - root - INFO - hit3: 0.51713\n",
      "2022-05-05 05:22:44,493 - root - INFO - hit10: 0.63018\n",
      "2022-05-05 05:22:44,493 - root - INFO - mr: 213.91904\n",
      "2022-05-05 05:22:44,494 - root - INFO - mrr: 0.47879472868532047\n",
      "2022-05-05 05:25:50,891 - root - INFO - 36     loss: 89505022.19726562\n",
      "2022-05-05 05:26:15,967 - root - INFO - --------------------\n",
      "2022-05-05 05:26:15,968 - root - INFO - hit1: 0.40051\n",
      "2022-05-05 05:26:15,969 - root - INFO - hit3: 0.52034\n",
      "2022-05-05 05:26:15,970 - root - INFO - hit10: 0.63245\n",
      "2022-05-05 05:26:15,970 - root - INFO - mr: 209.9166\n",
      "2022-05-05 05:26:15,971 - root - INFO - mrr: 0.48139029730850613\n",
      "2022-05-05 05:29:22,608 - root - INFO - 37     loss: 89133073.20117188\n",
      "2022-05-05 05:29:46,753 - root - INFO - --------------------\n",
      "2022-05-05 05:29:46,753 - root - INFO - hit1: 0.40446\n",
      "2022-05-05 05:29:46,754 - root - INFO - hit3: 0.52351\n",
      "2022-05-05 05:29:46,755 - root - INFO - hit10: 0.63627\n",
      "2022-05-05 05:29:46,756 - root - INFO - mr: 205.32857\n",
      "2022-05-05 05:29:46,756 - root - INFO - mrr: 0.4850566468488423\n",
      "2022-05-05 05:32:54,156 - root - INFO - 38     loss: 88740110.47265625\n",
      "2022-05-05 05:33:17,768 - root - INFO - --------------------\n",
      "2022-05-05 05:33:17,770 - root - INFO - hit1: 0.40633\n",
      "2022-05-05 05:33:17,771 - root - INFO - hit3: 0.52661\n",
      "2022-05-05 05:33:17,773 - root - INFO - hit10: 0.63937\n",
      "2022-05-05 05:33:17,773 - root - INFO - mr: 201.96906\n",
      "2022-05-05 05:33:17,774 - root - INFO - mrr: 0.48740481872812413\n",
      "2022-05-05 05:36:26,678 - root - INFO - 39     loss: 88397616.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 05:36:50,841 - root - INFO - --------------------\n",
      "2022-05-05 05:36:50,843 - root - INFO - hit1: 0.40931\n",
      "2022-05-05 05:36:50,844 - root - INFO - hit3: 0.52941\n",
      "2022-05-05 05:36:50,845 - root - INFO - hit10: 0.642\n",
      "2022-05-05 05:36:50,846 - root - INFO - mr: 197.74656\n",
      "2022-05-05 05:36:50,847 - root - INFO - mrr: 0.4902660975924878\n",
      "2022-05-05 05:39:58,629 - root - INFO - 40     loss: 88117521.11328125\n",
      "2022-05-05 05:40:22,534 - root - INFO - --------------------\n",
      "2022-05-05 05:40:22,535 - root - INFO - hit1: 0.41169\n",
      "2022-05-05 05:40:22,536 - root - INFO - hit3: 0.53172\n",
      "2022-05-05 05:40:22,536 - root - INFO - hit10: 0.64616\n",
      "2022-05-05 05:40:22,537 - root - INFO - mr: 195.13601\n",
      "2022-05-05 05:40:22,537 - root - INFO - mrr: 0.4929168621381835\n",
      "2022-05-05 05:43:29,707 - root - INFO - 41     loss: 87808325.81835938\n",
      "2022-05-05 05:43:53,971 - root - INFO - --------------------\n",
      "2022-05-05 05:43:53,973 - root - INFO - hit1: 0.4134\n",
      "2022-05-05 05:43:53,975 - root - INFO - hit3: 0.53457\n",
      "2022-05-05 05:43:53,977 - root - INFO - hit10: 0.64805\n",
      "2022-05-05 05:43:53,978 - root - INFO - mr: 191.80433\n",
      "2022-05-05 05:43:53,979 - root - INFO - mrr: 0.49494797378587907\n",
      "2022-05-05 05:47:02,224 - root - INFO - 42     loss: 87512931.44921875\n",
      "2022-05-05 05:47:26,461 - root - INFO - --------------------\n",
      "2022-05-05 05:47:26,463 - root - INFO - hit1: 0.41558\n",
      "2022-05-05 05:47:26,468 - root - INFO - hit3: 0.5373\n",
      "2022-05-05 05:47:26,472 - root - INFO - hit10: 0.65031\n",
      "2022-05-05 05:47:26,473 - root - INFO - mr: 189.31882\n",
      "2022-05-05 05:47:26,474 - root - INFO - mrr: 0.49727711378852246\n",
      "2022-05-05 05:50:32,935 - root - INFO - 43     loss: 87224113.62695312\n",
      "2022-05-05 05:50:56,728 - root - INFO - --------------------\n",
      "2022-05-05 05:50:56,729 - root - INFO - hit1: 0.41683\n",
      "2022-05-05 05:50:56,730 - root - INFO - hit3: 0.53889\n",
      "2022-05-05 05:50:56,730 - root - INFO - hit10: 0.65294\n",
      "2022-05-05 05:50:56,731 - root - INFO - mr: 186.22761\n",
      "2022-05-05 05:50:56,732 - root - INFO - mrr: 0.49897616814446955\n",
      "2022-05-05 05:54:04,808 - root - INFO - 44     loss: 86995620.35742188\n",
      "2022-05-05 05:54:28,605 - root - INFO - --------------------\n",
      "2022-05-05 05:54:28,606 - root - INFO - hit1: 0.41823\n",
      "2022-05-05 05:54:28,607 - root - INFO - hit3: 0.54098\n",
      "2022-05-05 05:54:28,607 - root - INFO - hit10: 0.65361\n",
      "2022-05-05 05:54:28,608 - root - INFO - mr: 184.57489\n",
      "2022-05-05 05:54:28,608 - root - INFO - mrr: 0.5004813692872331\n",
      "2022-05-05 05:57:38,074 - root - INFO - 45     loss: 86781910.56835938\n",
      "2022-05-05 05:58:02,096 - root - INFO - --------------------\n",
      "2022-05-05 05:58:02,098 - root - INFO - hit1: 0.42105\n",
      "2022-05-05 05:58:02,099 - root - INFO - hit3: 0.54338\n",
      "2022-05-05 05:58:02,100 - root - INFO - hit10: 0.65694\n",
      "2022-05-05 05:58:02,100 - root - INFO - mr: 182.10299\n",
      "2022-05-05 05:58:02,101 - root - INFO - mrr: 0.5032637084264703\n",
      "2022-05-05 06:01:09,814 - root - INFO - 46     loss: 86523541.35546875\n",
      "2022-05-05 06:01:33,731 - root - INFO - --------------------\n",
      "2022-05-05 06:01:33,733 - root - INFO - hit1: 0.42146\n",
      "2022-05-05 06:01:33,734 - root - INFO - hit3: 0.54508\n",
      "2022-05-05 06:01:33,734 - root - INFO - hit10: 0.65822\n",
      "2022-05-05 06:01:33,735 - root - INFO - mr: 180.05422\n",
      "2022-05-05 06:01:33,736 - root - INFO - mrr: 0.5040783238436839\n",
      "2022-05-05 06:04:42,512 - root - INFO - 47     loss: 86316865.98242188\n",
      "2022-05-05 06:05:06,359 - root - INFO - --------------------\n",
      "2022-05-05 06:05:06,360 - root - INFO - hit1: 0.4219\n",
      "2022-05-05 06:05:06,361 - root - INFO - hit3: 0.54743\n",
      "2022-05-05 06:05:06,361 - root - INFO - hit10: 0.66048\n",
      "2022-05-05 06:05:06,362 - root - INFO - mr: 178.2388\n",
      "2022-05-05 06:05:06,362 - root - INFO - mrr: 0.5054178866205431\n",
      "2022-05-05 06:08:14,069 - root - INFO - 48     loss: 86107418.52734375\n",
      "2022-05-05 06:08:38,236 - root - INFO - --------------------\n",
      "2022-05-05 06:08:38,241 - root - INFO - hit1: 0.42487\n",
      "2022-05-05 06:08:38,243 - root - INFO - hit3: 0.54941\n",
      "2022-05-05 06:08:38,244 - root - INFO - hit10: 0.66186\n",
      "2022-05-05 06:08:38,246 - root - INFO - mr: 176.21337\n",
      "2022-05-05 06:08:38,246 - root - INFO - mrr: 0.5076365985405786\n",
      "2022-05-05 06:11:45,694 - root - INFO - 49     loss: 85894036.41015625\n",
      "2022-05-05 06:12:09,188 - root - INFO - --------------------\n",
      "2022-05-05 06:12:09,189 - root - INFO - hit1: 0.4258\n",
      "2022-05-05 06:12:09,189 - root - INFO - hit3: 0.55147\n",
      "2022-05-05 06:12:09,190 - root - INFO - hit10: 0.66341\n",
      "2022-05-05 06:12:09,191 - root - INFO - mr: 174.01265\n",
      "2022-05-05 06:12:09,191 - root - INFO - mrr: 0.5090820127508098\n",
      "2022-05-05 06:15:16,340 - root - INFO - 50     loss: 85702139.6953125\n",
      "2022-05-05 06:15:40,673 - root - INFO - --------------------\n",
      "2022-05-05 06:15:40,674 - root - INFO - hit1: 0.42716\n",
      "2022-05-05 06:15:40,675 - root - INFO - hit3: 0.55299\n",
      "2022-05-05 06:15:40,676 - root - INFO - hit10: 0.6658\n",
      "2022-05-05 06:15:40,677 - root - INFO - mr: 172.19609\n",
      "2022-05-05 06:15:40,677 - root - INFO - mrr: 0.5105740456273611\n",
      "2022-05-05 06:18:49,097 - root - INFO - 51     loss: 85527529.15820312\n",
      "2022-05-05 06:19:13,158 - root - INFO - --------------------\n",
      "2022-05-05 06:19:13,160 - root - INFO - hit1: 0.42811\n",
      "2022-05-05 06:19:13,160 - root - INFO - hit3: 0.55411\n",
      "2022-05-05 06:19:13,161 - root - INFO - hit10: 0.66682\n",
      "2022-05-05 06:19:13,162 - root - INFO - mr: 171.0127\n",
      "2022-05-05 06:19:13,162 - root - INFO - mrr: 0.5115842450944817\n",
      "2022-05-05 06:22:21,582 - root - INFO - 52     loss: 85351160.8984375\n",
      "2022-05-05 06:22:46,892 - root - INFO - --------------------\n",
      "2022-05-05 06:22:46,893 - root - INFO - hit1: 0.42986\n",
      "2022-05-05 06:22:46,893 - root - INFO - hit3: 0.55587\n",
      "2022-05-05 06:22:46,894 - root - INFO - hit10: 0.66901\n",
      "2022-05-05 06:22:46,894 - root - INFO - mr: 169.44566\n",
      "2022-05-05 06:22:46,895 - root - INFO - mrr: 0.513348692544772\n",
      "2022-05-05 06:25:54,448 - root - INFO - 53     loss: 85187780.58007812\n",
      "2022-05-05 06:26:18,059 - root - INFO - --------------------\n",
      "2022-05-05 06:26:18,060 - root - INFO - hit1: 0.42999\n",
      "2022-05-05 06:26:18,061 - root - INFO - hit3: 0.55696\n",
      "2022-05-05 06:26:18,062 - root - INFO - hit10: 0.67035\n",
      "2022-05-05 06:26:18,062 - root - INFO - mr: 168.15451\n",
      "2022-05-05 06:26:18,063 - root - INFO - mrr: 0.51414687374364\n",
      "2022-05-05 06:29:25,602 - root - INFO - 54     loss: 85007242.02734375\n",
      "2022-05-05 06:29:49,400 - root - INFO - --------------------\n",
      "2022-05-05 06:29:49,402 - root - INFO - hit1: 0.43199\n",
      "2022-05-05 06:29:49,405 - root - INFO - hit3: 0.5584\n",
      "2022-05-05 06:29:49,406 - root - INFO - hit10: 0.67144\n",
      "2022-05-05 06:29:49,407 - root - INFO - mr: 167.02012\n",
      "2022-05-05 06:29:49,407 - root - INFO - mrr: 0.5157260875185667\n",
      "2022-05-05 06:32:55,639 - root - INFO - 55     loss: 84855482.74609375\n",
      "2022-05-05 06:33:20,553 - root - INFO - --------------------\n",
      "2022-05-05 06:33:20,554 - root - INFO - hit1: 0.43228\n",
      "2022-05-05 06:33:20,554 - root - INFO - hit3: 0.55937\n",
      "2022-05-05 06:33:20,555 - root - INFO - hit10: 0.67284\n",
      "2022-05-05 06:33:20,555 - root - INFO - mr: 165.76431\n",
      "2022-05-05 06:33:20,556 - root - INFO - mrr: 0.5164322285714114\n",
      "2022-05-05 06:36:26,504 - root - INFO - 56     loss: 84665937.63476562\n",
      "2022-05-05 06:36:50,218 - root - INFO - --------------------\n",
      "2022-05-05 06:36:50,219 - root - INFO - hit1: 0.43356\n",
      "2022-05-05 06:36:50,219 - root - INFO - hit3: 0.56099\n",
      "2022-05-05 06:36:50,220 - root - INFO - hit10: 0.67394\n",
      "2022-05-05 06:36:50,220 - root - INFO - mr: 163.97958\n",
      "2022-05-05 06:36:50,221 - root - INFO - mrr: 0.5179809801271575\n",
      "2022-05-05 06:39:57,375 - root - INFO - 57     loss: 84556538.86328125\n",
      "2022-05-05 06:40:21,552 - root - INFO - --------------------\n",
      "2022-05-05 06:40:21,553 - root - INFO - hit1: 0.43556\n",
      "2022-05-05 06:40:21,553 - root - INFO - hit3: 0.56337\n",
      "2022-05-05 06:40:21,554 - root - INFO - hit10: 0.67614\n",
      "2022-05-05 06:40:21,554 - root - INFO - mr: 162.52672\n",
      "2022-05-05 06:40:21,554 - root - INFO - mrr: 0.519736455570043\n",
      "2022-05-05 06:43:29,214 - root - INFO - 58     loss: 84397740.06640625\n",
      "2022-05-05 06:43:53,062 - root - INFO - --------------------\n",
      "2022-05-05 06:43:53,064 - root - INFO - hit1: 0.4357\n",
      "2022-05-05 06:43:53,065 - root - INFO - hit3: 0.5642\n",
      "2022-05-05 06:43:53,066 - root - INFO - hit10: 0.67675\n",
      "2022-05-05 06:43:53,066 - root - INFO - mr: 161.64802\n",
      "2022-05-05 06:43:53,067 - root - INFO - mrr: 0.5203880430249622\n",
      "2022-05-05 06:47:01,896 - root - INFO - 59     loss: 84258160.86523438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 06:47:26,147 - root - INFO - --------------------\n",
      "2022-05-05 06:47:26,148 - root - INFO - hit1: 0.43683\n",
      "2022-05-05 06:47:26,149 - root - INFO - hit3: 0.56524\n",
      "2022-05-05 06:47:26,150 - root - INFO - hit10: 0.67773\n",
      "2022-05-05 06:47:26,151 - root - INFO - mr: 160.34693\n",
      "2022-05-05 06:47:26,152 - root - INFO - mrr: 0.5213775612828307\n",
      "2022-05-05 06:50:33,675 - root - INFO - 60     loss: 84113496.421875\n",
      "2022-05-05 06:50:57,487 - root - INFO - --------------------\n",
      "2022-05-05 06:50:57,488 - root - INFO - hit1: 0.43785\n",
      "2022-05-05 06:50:57,489 - root - INFO - hit3: 0.56682\n",
      "2022-05-05 06:50:57,489 - root - INFO - hit10: 0.67902\n",
      "2022-05-05 06:50:57,490 - root - INFO - mr: 159.11039\n",
      "2022-05-05 06:50:57,490 - root - INFO - mrr: 0.5226494098998804\n",
      "2022-05-05 06:54:05,033 - root - INFO - 61     loss: 83972438.68164062\n",
      "2022-05-05 06:54:28,843 - root - INFO - --------------------\n",
      "2022-05-05 06:54:28,844 - root - INFO - hit1: 0.43816\n",
      "2022-05-05 06:54:28,845 - root - INFO - hit3: 0.56764\n",
      "2022-05-05 06:54:28,845 - root - INFO - hit10: 0.68011\n",
      "2022-05-05 06:54:28,846 - root - INFO - mr: 158.20522\n",
      "2022-05-05 06:54:28,846 - root - INFO - mrr: 0.5229725481402642\n",
      "2022-05-05 06:57:34,578 - root - INFO - 62     loss: 83836990.91796875\n",
      "2022-05-05 06:57:58,250 - root - INFO - --------------------\n",
      "2022-05-05 06:57:58,251 - root - INFO - hit1: 0.43898\n",
      "2022-05-05 06:57:58,251 - root - INFO - hit3: 0.56901\n",
      "2022-05-05 06:57:58,252 - root - INFO - hit10: 0.6815\n",
      "2022-05-05 06:57:58,253 - root - INFO - mr: 156.62222\n",
      "2022-05-05 06:57:58,253 - root - INFO - mrr: 0.5241983989876462\n",
      "2022-05-05 07:01:07,092 - root - INFO - 63     loss: 83711374.16210938\n",
      "2022-05-05 07:01:31,151 - root - INFO - --------------------\n",
      "2022-05-05 07:01:31,152 - root - INFO - hit1: 0.44053\n",
      "2022-05-05 07:01:31,153 - root - INFO - hit3: 0.56929\n",
      "2022-05-05 07:01:31,153 - root - INFO - hit10: 0.68209\n",
      "2022-05-05 07:01:31,154 - root - INFO - mr: 156.22035\n",
      "2022-05-05 07:01:31,154 - root - INFO - mrr: 0.5253659246757436\n",
      "2022-05-05 07:04:38,647 - root - INFO - 64     loss: 83605119.625\n",
      "2022-05-05 07:05:02,156 - root - INFO - --------------------\n",
      "2022-05-05 07:05:02,157 - root - INFO - hit1: 0.44195\n",
      "2022-05-05 07:05:02,157 - root - INFO - hit3: 0.57078\n",
      "2022-05-05 07:05:02,158 - root - INFO - hit10: 0.68262\n",
      "2022-05-05 07:05:02,159 - root - INFO - mr: 155.24192\n",
      "2022-05-05 07:05:02,159 - root - INFO - mrr: 0.5264845334490361\n",
      "2022-05-05 07:08:10,212 - root - INFO - 65     loss: 83504927.23242188\n",
      "2022-05-05 07:08:33,877 - root - INFO - --------------------\n",
      "2022-05-05 07:08:33,878 - root - INFO - hit1: 0.44164\n",
      "2022-05-05 07:08:33,879 - root - INFO - hit3: 0.57153\n",
      "2022-05-05 07:08:33,879 - root - INFO - hit10: 0.68284\n",
      "2022-05-05 07:08:33,880 - root - INFO - mr: 154.8688\n",
      "2022-05-05 07:08:33,880 - root - INFO - mrr: 0.526737008636894\n",
      "2022-05-05 07:11:41,210 - root - INFO - 66     loss: 83379843.46679688\n",
      "2022-05-05 07:12:04,874 - root - INFO - --------------------\n",
      "2022-05-05 07:12:04,875 - root - INFO - hit1: 0.44305\n",
      "2022-05-05 07:12:04,876 - root - INFO - hit3: 0.57353\n",
      "2022-05-05 07:12:04,876 - root - INFO - hit10: 0.68421\n",
      "2022-05-05 07:12:04,877 - root - INFO - mr: 153.04418\n",
      "2022-05-05 07:12:04,877 - root - INFO - mrr: 0.5281136255598542\n",
      "2022-05-05 07:15:14,100 - root - INFO - 67     loss: 83274602.11523438\n",
      "2022-05-05 07:15:37,950 - root - INFO - --------------------\n",
      "2022-05-05 07:15:37,951 - root - INFO - hit1: 0.44308\n",
      "2022-05-05 07:15:37,951 - root - INFO - hit3: 0.57285\n",
      "2022-05-05 07:15:37,952 - root - INFO - hit10: 0.68557\n",
      "2022-05-05 07:15:37,953 - root - INFO - mr: 152.3366\n",
      "2022-05-05 07:15:37,953 - root - INFO - mrr: 0.5284240074476444\n",
      "2022-05-05 07:18:44,713 - root - INFO - 68     loss: 83178923.16601562\n",
      "2022-05-05 07:19:08,229 - root - INFO - --------------------\n",
      "2022-05-05 07:19:08,230 - root - INFO - hit1: 0.44343\n",
      "2022-05-05 07:19:08,231 - root - INFO - hit3: 0.57433\n",
      "2022-05-05 07:19:08,232 - root - INFO - hit10: 0.68614\n",
      "2022-05-05 07:19:08,232 - root - INFO - mr: 151.9684\n",
      "2022-05-05 07:19:08,233 - root - INFO - mrr: 0.5287952711941297\n",
      "2022-05-05 07:22:14,600 - root - INFO - 69     loss: 83067290.578125\n",
      "2022-05-05 07:22:38,418 - root - INFO - --------------------\n",
      "2022-05-05 07:22:38,419 - root - INFO - hit1: 0.4432\n",
      "2022-05-05 07:22:38,420 - root - INFO - hit3: 0.5749\n",
      "2022-05-05 07:22:38,421 - root - INFO - hit10: 0.68646\n",
      "2022-05-05 07:22:38,421 - root - INFO - mr: 150.84979\n",
      "2022-05-05 07:22:38,422 - root - INFO - mrr: 0.52911483193182\n",
      "2022-05-05 07:25:46,526 - root - INFO - 70     loss: 83004816.78320312\n",
      "2022-05-05 07:26:10,579 - root - INFO - --------------------\n",
      "2022-05-05 07:26:10,581 - root - INFO - hit1: 0.44485\n",
      "2022-05-05 07:26:10,582 - root - INFO - hit3: 0.57613\n",
      "2022-05-05 07:26:10,582 - root - INFO - hit10: 0.68821\n",
      "2022-05-05 07:26:10,583 - root - INFO - mr: 150.14268\n",
      "2022-05-05 07:26:10,584 - root - INFO - mrr: 0.53036310757317\n",
      "2022-05-05 07:29:17,917 - root - INFO - 71     loss: 82890334.2890625\n",
      "2022-05-05 07:29:42,304 - root - INFO - --------------------\n",
      "2022-05-05 07:29:42,305 - root - INFO - hit1: 0.44578\n",
      "2022-05-05 07:29:42,306 - root - INFO - hit3: 0.57737\n",
      "2022-05-05 07:29:42,307 - root - INFO - hit10: 0.68826\n",
      "2022-05-05 07:29:42,307 - root - INFO - mr: 149.55464\n",
      "2022-05-05 07:29:42,308 - root - INFO - mrr: 0.5313303408656345\n",
      "2022-05-05 07:32:49,879 - root - INFO - 72     loss: 82790703.62304688\n",
      "2022-05-05 07:33:14,232 - root - INFO - --------------------\n",
      "2022-05-05 07:33:14,233 - root - INFO - hit1: 0.44657\n",
      "2022-05-05 07:33:14,234 - root - INFO - hit3: 0.57886\n",
      "2022-05-05 07:33:14,235 - root - INFO - hit10: 0.68986\n",
      "2022-05-05 07:33:14,235 - root - INFO - mr: 148.8231\n",
      "2022-05-05 07:33:14,236 - root - INFO - mrr: 0.5324622764079163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CrossE(config)  \n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(myLoadData, config, model)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m tot_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (h, h_l, t,t_l) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmyTrainDataSet.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     13\u001b[0m     h_triple \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_hr_tlist[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriple\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m     h_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_hr_tlist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m     t_triple \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_tr_hlist[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriple\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m     t_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetlabel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_tr_hlist[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmyTrainDataSet.getlabel\u001b[0;34m(self, labels_list)\u001b[0m\n\u001b[1;32m     24\u001b[0m     labels[label] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ment_num\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "myLoadData = loadData(config)\n",
    "config.init_num(myLoadData.get_ent_num(), myLoadData.get_rel_num())\n",
    "model = CrossE(config)  \n",
    "\n",
    "\n",
    "trainer = Trainer(myLoadData, config, model)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(config.model_path+\"/\"+config.file_name+\"-best_model.pkl\"))\n",
    "class Tester:\n",
    "    def __init__(self,myLoadData, config, model):\n",
    "        self.config = config\n",
    "        self.device = config.device \n",
    "        self.model = model.to(config.device)\n",
    "        testdata = myTestDateSet(myLoadData, config, 'test')\n",
    "        self.loader_test = DataLoader(testdata, batch_size = config.eval_batch, shuffle = True)\n",
    "#         self.epochs = config.epochs\n",
    "        self.fact_num = len(testdata)\n",
    "    def eval_valid(self):\n",
    "        self.model.eval()\n",
    "        best_acc = 0.0\n",
    "        for i, (h, h_l, t,t_l) in enumerate(self.test_loader):\n",
    "            h = h.to(self.device)\n",
    "            h_l = h_l.to(self.device)\n",
    "            t = t.to(self.device)\n",
    "            t_l = t_l.to(self.device)\n",
    "            h_pred, t_pred= self.model.pred(h, h_l, t, t_l)\n",
    "            \n",
    "            h_target = h[:,-1]\n",
    "            t_target = h[:, -1]\n",
    "            self.pred(h_pred, h_l, h_target)\n",
    "            self.pred(t_pred, t_l, t_target)\n",
    "        acc = self.measure.deal(self.fact_num)\n",
    "        self.measure.print_()\n",
    "    \n",
    "    def pred(self, pred, labels, t):\n",
    "        batch = pred.shape[0]\n",
    "        pred_size = torch.arange(batch)\n",
    "        target = pred[pred_size,t]\n",
    "        pred = torch.where(labels.byte(), torch.zeros_like(pred), pred)\n",
    "        pred[pred_size, t] = target\n",
    "        pred = pred.cpu()numpy()\n",
    "        t = t.cpu().numpy()\n",
    "        for i in range(batch):\n",
    "            e = t[i]\n",
    "            one_pred = pred[i]\n",
    "            aim = one_pred[e]\n",
    "            sc = np.delete(one_pred, e)\n",
    "            sc = np.insert(sc, 0, aim)\n",
    "            rank = (sc[0] <= sc).sum()\n",
    "            self.measure.update(rank)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be2045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
