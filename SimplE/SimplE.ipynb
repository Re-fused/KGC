{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4ecd13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "class DataSet:\n",
    "    def __init__(self, ds_name):\n",
    "        self.name = ds_name\n",
    "        self.dir =  \"/home/qiupp/code/SimplE-master/datasets/\"+ds_name+\"/\"\n",
    "        self.ent2id = {}\n",
    "        self.rel2id = {}\n",
    "        self.data = {spl: self.read(self.dir + spl + \".txt\") for spl in [\"train\", \"valid\", \"test\"]}\n",
    "        self.batch_index = 0\n",
    "    def read(self, file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        triples = np.zeros((len(lines), 3))\n",
    "        for i, line in enumerate(lines):\n",
    "            triples[i] = np.array(self.triple2ids(line.strip().split(\"\\t\")))\n",
    "        return triples\n",
    "    \n",
    "    def get_ent_num(self):\n",
    "        return len(self.ent2id)\n",
    "    \n",
    "    def get_rel_num(self):\n",
    "        return len(self.rel2id)\n",
    "                     \n",
    "    def triple2ids(self, triple):\n",
    "        return [self.get_ent_id(triple[0]), self.get_rel_id(triple[1]), self.get_ent_id(triple[2])]\n",
    "                     \n",
    "    def get_ent_id(self, ent):\n",
    "        if not ent in self.ent2id:\n",
    "            self.ent2id[ent] = len(self.ent2id)\n",
    "        return self.ent2id[ent]\n",
    "            \n",
    "    def get_rel_id(self, rel):\n",
    "        if not rel in self.rel2id:\n",
    "            self.rel2id[rel] = len(self.rel2id)\n",
    "        return self.rel2id[rel]\n",
    "                     \n",
    "    def rand_ent_except(self, ent):\n",
    "        rand_ent = random.randint(0, self.get_ent_num() - 1)\n",
    "        while(rand_ent == ent):\n",
    "            rand_ent = random.randint(0, self.get_ent_num() - 1)\n",
    "        return rand_ent\n",
    "                     \n",
    "    def next_pos_batch(self, batch_size):\n",
    "        if self.batch_index + batch_size < len(self.data[\"train\"]):\n",
    "            batch = self.data[\"train\"][self.batch_index: self.batch_index+batch_size]\n",
    "            self.batch_index += batch_size\n",
    "        else:\n",
    "            batch = self.data[\"train\"][self.batch_index:]\n",
    "            self.batch_index = 0\n",
    "        return np.append(batch, np.ones((len(batch), 1)), axis=1).astype(\"int\") #appending the +1 label\n",
    "                     \n",
    "    def generate_neg(self, pos_batch, neg_ratio):\n",
    "        neg_batch = np.repeat(np.copy(pos_batch), neg_ratio, axis=0)\n",
    "        for i in range(len(neg_batch)):\n",
    "            if random.random() < 0.5:\n",
    "                neg_batch[i][0] = self.rand_ent_except(neg_batch[i][0]) #flipping head\n",
    "            else:\n",
    "                neg_batch[i][2] = self.rand_ent_except(neg_batch[i][2]) #flipping tail\n",
    "        neg_batch[:,-1] = -1\n",
    "        return neg_batch\n",
    "\n",
    "    def next_batch(self, batch_size, neg_ratio, device):\n",
    "        pos_batch = self.next_pos_batch(batch_size)\n",
    "        neg_batch = self.generate_neg(pos_batch, neg_ratio)\n",
    "        batch = np.append(pos_batch, neg_batch, axis=0)\n",
    "        np.random.shuffle(batch)\n",
    "        heads  = torch.tensor(batch[:,0]).long().to(device)\n",
    "        rels   = torch.tensor(batch[:,1]).long().to(device)\n",
    "        tails  = torch.tensor(batch[:,2]).long().to(device)\n",
    "        labels = torch.tensor(batch[:,3]).float().to(device)\n",
    "        return heads, rels, tails, labels\n",
    "    \n",
    "    def was_last_batch(self):\n",
    "        return (self.batch_index == 0)\n",
    "\n",
    "    def num_batch(self, batch_size):\n",
    "        return int(math.ceil(float(len(self.data[\"train\"])) / batch_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8813617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataseta = DataSet(\"WN18\")\n",
    "#print(dataset.next_batch(10, 1, 'cpu'))\n",
    "#print(dataset.get_ent_num())\n",
    "#print(dataset.get_rel_num())\n",
    "#print(dataset.num_batch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8f0905b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class SimplE(nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, emb_dim, device):\n",
    "        super(SimplE, self).__init__()\n",
    "        self.num_ent = num_ent\n",
    "        self.num_rel = num_rel\n",
    "        self.emb_dim = emb_dim\n",
    "        self.device = device\n",
    "\t\t#进行配置两个实体的embedding和两个关系的embedding\n",
    "\t\t#头实体的embedding\n",
    "        self.ent_h_embs   = nn.Embedding(num_ent, emb_dim).to(device)\n",
    "\t\t#尾实体的embedding \n",
    "        self.ent_t_embs   = nn.Embedding(num_ent, emb_dim).to(device)\n",
    "\t\t#正关系的embedding\n",
    "        self.rel_embs     = nn.Embedding(num_rel, emb_dim).to(device)\n",
    "\t\t#逆关系的embedding\n",
    "        self.rel_inv_embs = nn.Embedding(num_rel, emb_dim).to(device)\n",
    "\n",
    "        sqrt_size = 6.0 / math.sqrt(self.emb_dim)\n",
    "\t\t#embedding 参数进行初始化\n",
    "        nn.init.uniform_(self.ent_h_embs.weight.data, -sqrt_size, sqrt_size)\n",
    "        nn.init.uniform_(self.ent_t_embs.weight.data, -sqrt_size, sqrt_size)\n",
    "        nn.init.uniform_(self.rel_embs.weight.data, -sqrt_size, sqrt_size)\n",
    "        nn.init.uniform_(self.rel_inv_embs.weight.data, -sqrt_size, sqrt_size)\n",
    "        \n",
    "\t#embedding 参数l2范式\n",
    "    def l2_loss(self):\n",
    "        return ((torch.norm(self.ent_h_embs.weight, p=2) ** 2) + (torch.norm(self.ent_t_embs.weight, p=2) ** 2) + (torch.norm(self.rel_embs.weight, p=2) ** 2) + (torch.norm(self.rel_inv_embs.weight, p=2) ** 2)) / 2\n",
    "\n",
    "    def forward(self, heads, rels, tails):\n",
    "        hh_embs = self.ent_h_embs(heads)\n",
    "        #print(hh_embs, hh_embs.shape)\n",
    "        ht_embs = self.ent_h_embs(tails)\n",
    "        th_embs = self.ent_t_embs(heads)\n",
    "        tt_embs = self.ent_t_embs(tails)\n",
    "        r_embs = self.rel_embs(rels)\n",
    "        r_inv_embs = self.rel_inv_embs(rels)\n",
    "\n",
    "        scores1 = torch.sum(hh_embs * r_embs * tt_embs, dim=1)\n",
    "        scores2 = torch.sum(ht_embs * r_inv_embs * th_embs, dim=1)\n",
    "\t\t#核心score函数\n",
    "        return torch.clamp((scores1 + scores2) / 2, -20, 20)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "430bcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h = torch.LongTensor([1, 2, 3, 3, 4, 4, 5, 6])\n",
    "#r = torch.LongTensor([1, 2, 3, 3, 4, 4, 5, 6])\n",
    "#t = torch.LongTensor([1, 2, 3, 3, 4, 4, 5, 6])\n",
    "#model = SimplE(10, 10, 10, 'cpu')\n",
    "#print(model(h, r, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ccd8a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "class Trainer:\n",
    "    def __init__(self, dataset, args):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = SimplE(dataset.get_ent_num(), dataset.get_rel_num(), args.dim, self.device)\n",
    "        self.dataset = dataset\n",
    "        self.args = args\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = torch.optim.Adagrad(\n",
    "            self.model.parameters(),\n",
    "            lr=self.args.lr,\n",
    "            weight_decay= 0,\n",
    "            initial_accumulator_value= 0.1 #this is added because of the consistency to the original tensorflow code\n",
    "        )\n",
    "\t\t#进行训练\n",
    "        for epoch in range(1, self.args.ne + 1):\n",
    "            last_batch = False\n",
    "            total_loss = 0.0\n",
    "            while not last_batch:\n",
    "                h, r, t, l = self.dataset.next_batch(self.args.batch_size, neg_ratio=self.args.neg_ratio, device = self.device)\n",
    "                last_batch = self.dataset.was_last_batch()\n",
    "                optimizer.zero_grad()\n",
    "                scores = self.model(h, r, t)\n",
    "                loss = torch.sum(F.softplus(-l * scores))+ (self.args.reg_lambda * self.model.l2_loss() / self.dataset.num_batch(self.args.batch_size))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.cpu().item()\n",
    "\n",
    "            print(\"Loss in iteration \" + str(epoch) + \": \" + str(total_loss) + \"(\" + self.dataset.name + \")\")\n",
    "        \n",
    "            if epoch % self.args.save_each == 0:\n",
    "                self.save_model(epoch)\n",
    "    def save_model(self, chkpnt):\n",
    "        print(\"Saving the model\")\n",
    "        directory = \"/home/qiupp/code/SimplE-master/models/\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save(self.model, directory + str(chkpnt) + \".chkpnt\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0554efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure:\n",
    "    def __init__(self):\n",
    "        self.hit1  = {\"raw\": 0.0, \"fil\": 0.0}\n",
    "        self.hit3  = {\"raw\": 0.0, \"fil\": 0.0}\n",
    "        self.hit10 = {\"raw\": 0.0, \"fil\": 0.0}\n",
    "        self.mrr   = {\"raw\": 0.0, \"fil\": 0.0}\n",
    "        self.mr    = {\"raw\": 0.0, \"fil\": 0.0}\n",
    "\n",
    "    def update(self, rank, raw_or_fil):\n",
    "        if rank == 1:\n",
    "            self.hit1[raw_or_fil] += 1.0\n",
    "        if rank <= 3:\n",
    "            self.hit3[raw_or_fil] += 1.0\n",
    "        if rank <= 10:\n",
    "            self.hit10[raw_or_fil] += 1.0\n",
    "\n",
    "        self.mr[raw_or_fil]  += rank\n",
    "        self.mrr[raw_or_fil] += (1.0 / rank)\n",
    "    \n",
    "    def normalize(self, num_facts):\n",
    "        for raw_or_fil in [\"raw\", \"fil\"]:\n",
    "            self.hit1[raw_or_fil]  /= (2 * num_facts)\n",
    "            self.hit3[raw_or_fil]  /= (2 * num_facts)\n",
    "            self.hit10[raw_or_fil] /= (2 * num_facts)\n",
    "            self.mr[raw_or_fil]    /= (2 * num_facts)\n",
    "            self.mrr[raw_or_fil]   /= (2 * num_facts)\n",
    "\n",
    "    def print_(self):\n",
    "        for raw_or_fil in [\"raw\", \"fil\"]:\n",
    "            print(raw_or_fil.title() + \" setting:\")\n",
    "            print(\"\\tHit@1 =\",  self.hit1[raw_or_fil])\n",
    "            print(\"\\tHit@3 =\",  self.hit3[raw_or_fil])\n",
    "            print(\"\\tHit@10 =\", self.hit10[raw_or_fil])\n",
    "            print(\"\\tMR =\",     self.mr[raw_or_fil])\n",
    "            print(\"\\tMRR =\",    self.mrr[raw_or_fil])\n",
    "            print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba0028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, dataset, model_path, valid_or_test):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = torch.load(model_path, map_location = self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.dataset = dataset\n",
    "        self.valid_or_test = valid_or_test\n",
    "        self.measure = Measure()\n",
    "        self.all_facts_as_set_of_tuples = set(self.allFactsAsTuples())\n",
    "\n",
    "    def get_rank(self, sim_scores):#assuming the test fact is the first one\n",
    "        return (sim_scores >= sim_scores[0]).sum()\n",
    "\n",
    "    def create_queries(self, fact, head_or_tail):\n",
    "        head, rel, tail = fact\n",
    "        if head_or_tail == \"head\":\n",
    "            return [(i, rel, tail) for i in range(self.dataset.get_ent_num())]\n",
    "        elif head_or_tail == \"tail\":\n",
    "            return [(head, rel, i) for i in range(self.dataset.get_ent_num())]\n",
    "\n",
    "    def add_fact_and_shred(self, fact, queries, raw_or_fil):\n",
    "        if raw_or_fil == \"raw\":\n",
    "            result = [tuple(fact)] + queries\n",
    "        elif raw_or_fil == \"fil\":\n",
    "            result = [tuple(fact)] + list(set(queries) - self.all_facts_as_set_of_tuples)\n",
    "\n",
    "        return self.shred_facts(result)\n",
    "\n",
    "    # def replace_and_shred(self, fact, raw_or_fil, head_or_tail):\n",
    "    #     ret_facts = []\n",
    "    #     head, rel, tail = fact\n",
    "    #     for i in range(self.dataset.num_ent()):\n",
    "    #         if head_or_tail == \"head\" and i != head:\n",
    "    #             ret_facts.append((i, rel, tail))\n",
    "    #         if head_or_tail == \"tail\" and i != tail:\n",
    "    #             ret_facts.append((head, rel, i))\n",
    "\n",
    "    #     if raw_or_fil == \"raw\":\n",
    "    #         ret_facts = [tuple(fact)] + ret_facts\n",
    "    #     elif raw_or_fil == \"fil\":\n",
    "    #         ret_facts = [tuple(fact)] + list(set(ret_facts) - self.all_facts_as_set_of_tuples)\n",
    "\n",
    "    #     return self.shred_facts(ret_facts)\n",
    "    \n",
    "    def test(self):\n",
    "        settings = [\"raw\", \"fil\"] if self.valid_or_test == \"test\" else [\"fil\"]\n",
    "        \n",
    "        for i, fact in enumerate(self.dataset.data[self.valid_or_test]):\n",
    "            for head_or_tail in [\"head\", \"tail\"]:\n",
    "                queries = self.create_queries(fact, head_or_tail)\n",
    "                for raw_or_fil in settings:\n",
    "                    h, r, t = self.add_fact_and_shred(fact, queries, raw_or_fil)\n",
    "                    sim_scores = self.model(h, r, t).cpu().data.numpy()\n",
    "                    rank = self.get_rank(sim_scores)\n",
    "                    self.measure.update(rank, raw_or_fil)\n",
    "\n",
    "        self.measure.normalize(len(self.dataset.data[self.valid_or_test]))\n",
    "        self.measure.print_()\n",
    "        return self.measure.mrr[\"fil\"]\n",
    "\n",
    "    def shred_facts(self, triples):\n",
    "        heads  = [triples[i][0] for i in range(len(triples))]\n",
    "        rels   = [triples[i][1] for i in range(len(triples))]\n",
    "        tails  = [triples[i][2] for i in range(len(triples))]\n",
    "        return torch.LongTensor(heads).to(self.device), torch.LongTensor(rels).to(self.device), torch.LongTensor(tails).to(self.device)\n",
    "\n",
    "    def allFactsAsTuples(self):\n",
    "        tuples = []\n",
    "        for spl in self.dataset.data:\n",
    "            for fact in self.dataset.data[spl]:\n",
    "                tuples.append(tuple(fact))\n",
    "        \n",
    "        return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79393b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#args = get_parameter()\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#print(args.dataset)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[0;32m---> 30\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataSet\u001b[49m(args\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~~~~ Training ~~~~\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m Trainer(dataset, args)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataSet' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "class Args:\n",
    "    def __init__(self, ne =  1000,lr = 0.1, reg_lambda = 0.03, dataset = \"WN18\", \n",
    "                 emb_dim = 200, neg_ratio = 1,batch_size = 1415, save_each = 50):\n",
    "        self.ne = ne\n",
    "        self.lr = lr\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.dataset = dataset\n",
    "        self.dim = emb_dim\n",
    "        self.neg_ratio = neg_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.save_each = save_each\n",
    "def get_parameter():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-ne', default=1000, type=int, help=\"number of epochs\")\n",
    "    parser.add_argument('-lr', default=0.1, type=float, help=\"learning rate\")\n",
    "    parser.add_argument('-reg_lambda', default=0.03, type=float, help=\"l2 regularization parameter\")\n",
    "    parser.add_argument('-dataset', default=\"WN18\", type=str, help=\"wordnet dataset\")\n",
    "    parser.add_argument('-emb_dim', default=200, type=int, help=\"embedding dimension\")\n",
    "    parser.add_argument('-neg_ratio', default=1, type=int, help=\"number of negative examples per positive example\")\n",
    "    parser.add_argument('-batch_size', default=1415, type=int, help=\"batch size\")\n",
    "    parser.add_argument('-save_each', default=50, type=int, help=\"validate every k epochs\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "if __name__ == '__main__':\n",
    "    #args = get_parameter()\n",
    "    #print(args.dataset)\n",
    "    args = Args()\n",
    "    dataset = DataSet(args.dataset)\n",
    "\n",
    "    print(\"~~~~ Training ~~~~\")\n",
    "    trainer = Trainer(dataset, args)\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"~~~~ Select best epoch on validation set ~~~~\")\n",
    "    epochs2test = [str(int(args.save_each * (i + 1))) for i in range(args.ne // args.save_each)]\n",
    "    dataset = DataSet(args.dataset)\n",
    "    \n",
    "    best_mrr = -1.0\n",
    "    best_epoch = \"0\"\n",
    "    for epoch in epochs2test:\n",
    "        start = time.time()\n",
    "        print(epoch)\n",
    "        model_path = \"/home/qiupp/code/SimplE-master/models/\"+ epoch + \".chkpnt\"\n",
    "        tester = Tester(dataset, model_path, \"valid\")\n",
    "        mrr = tester.test()\n",
    "        if mrr > best_mrr:\n",
    "            best_mrr = mrr\n",
    "            best_epoch = epoch\n",
    "        print(time.time() - start)\n",
    "\n",
    "    print(\"Best epoch: \" + best_epoch)\n",
    "\n",
    "    print(\"~~~~ Testing on the best epoch ~~~~\")\n",
    "    best_model_path = \"/home/qiupp/code/SimplE-master/models//\" + best_epoch + \".chkpnt\"\n",
    "    tester = Tester(dataset, best_model_path, \"test\")\n",
    "    tester.test()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4832b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Select best epoch on validation set ~~~~\n",
      "['100']\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3763006/4101782626.py:65: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return torch.LongTensor(heads).to(self.device), torch.LongTensor(rels).to(self.device), torch.LongTensor(tails).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw setting:\n",
      "\tHit@1 = 0.0\n",
      "\tHit@3 = 0.0\n",
      "\tHit@10 = 0.0\n",
      "\tMR = 0.0\n",
      "\tMRR = 0.0\n",
      "\n",
      "Fil setting:\n",
      "\tHit@1 = 0.9146\n",
      "\tHit@3 = 0.9377\n",
      "\tHit@10 = 0.9395\n",
      "\tMR = 1104.0212\n",
      "\tMRR = 0.9262336059062445\n",
      "\n",
      "840.1743710041046\n",
      "Best epoch: 100\n",
      "~~~~ Testing on the best epoch ~~~~\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [210]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/qiupp/code/SimplE-master/models/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m best_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.chkpnt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m tester \u001b[38;5;241m=\u001b[39m Tester(dataset, best_model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [208]\u001b[0m, in \u001b[0;36mTester.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_queries(fact, head_or_tail)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m raw_or_fil \u001b[38;5;129;01min\u001b[39;00m settings:\n\u001b[0;32m---> 52\u001b[0m     h, r, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_fact_and_shred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_or_fil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     sim_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(h, r, t)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     54\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rank(sim_scores)\n",
      "Input \u001b[0;32mIn [208]\u001b[0m, in \u001b[0;36mTester.add_fact_and_shred\u001b[0;34m(self, fact, queries, raw_or_fil)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m raw_or_fil \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfil\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(fact)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(queries) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_facts_as_set_of_tuples)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshred_facts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [208]\u001b[0m, in \u001b[0;36mTester.shred_facts\u001b[0;34m(self, triples)\u001b[0m\n\u001b[1;32m     62\u001b[0m heads  \u001b[38;5;241m=\u001b[39m [triples[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[1;32m     63\u001b[0m rels   \u001b[38;5;241m=\u001b[39m [triples[i][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[0;32m---> 64\u001b[0m tails  \u001b[38;5;241m=\u001b[39m [triples[i][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mLongTensor(heads)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), torch\u001b[38;5;241m.\u001b[39mLongTensor(rels)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), torch\u001b[38;5;241m.\u001b[39mLongTensor(tails)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Input \u001b[0;32mIn [208]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m heads  \u001b[38;5;241m=\u001b[39m [triples[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[1;32m     63\u001b[0m rels   \u001b[38;5;241m=\u001b[39m [triples[i][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[0;32m---> 64\u001b[0m tails  \u001b[38;5;241m=\u001b[39m [\u001b[43mtriples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(triples))]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mLongTensor(heads)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), torch\u001b[38;5;241m.\u001b[39mLongTensor(rels)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), torch\u001b[38;5;241m.\u001b[39mLongTensor(tails)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Args:\n",
    "    def __init__(self, ne =  1000,lr = 0.1, reg_lambda = 0.03, dataset = \"WN18\", \n",
    "                 emb_dim = 200, neg_ratio = 1,batch_size = 1415, save_each = 50):\n",
    "        self.ne = ne\n",
    "        self.lr = lr\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.dataset = dataset\n",
    "        self.dim = emb_dim\n",
    "        self.neg_ratio = neg_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.save_each = save_each\n",
    "if __name__ == '__main__':\n",
    "    print(\"~~~~ Select best epoch on validation set ~~~~\")\n",
    "    args = Args()\n",
    "    #epochs2test = [str(int(args.save_each * (i + 1))) for i in range(2,args.ne // args.save_each)]\n",
    "    epochs2test = [\"100\"]\n",
    "    dataset = DataSet(args.dataset)\n",
    "    print(epochs2test)\n",
    "    \n",
    "    best_mrr = -1.0\n",
    "    best_epoch = \"0\"\n",
    "    for epoch in epochs2test:\n",
    "        start = time.time()\n",
    "        print(epoch)\n",
    "        model_path = '/home/qiupp/code/SimplE-master/models/'+ epoch + \".chkpnt\"\n",
    "        tester = Tester(dataset, model_path, \"valid\")\n",
    "        mrr = tester.test()\n",
    "        if mrr > best_mrr:\n",
    "            best_mrr = mrr\n",
    "            best_epoch = epoch\n",
    "        print(time.time() - start)\n",
    "\n",
    "    print(\"Best epoch: \" + best_epoch)\n",
    "\n",
    "    print(\"~~~~ Testing on the best epoch ~~~~\")\n",
    "    best_model_path = '/home/qiupp/code/SimplE-master/models/'+ best_epoch + \".chkpnt\"\n",
    "    tester = Tester(dataset, best_model_path, \"test\")\n",
    "    tester.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2590fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.jit.load( '/home/qiupp/code/SimplE-master/models/200.chkpnt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62263bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
